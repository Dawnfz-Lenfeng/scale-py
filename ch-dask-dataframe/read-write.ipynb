{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(dask-read-write)=\n",
    "# Reading and Writing Data\n",
    "\n",
    "Dask DataFrame supports nearly all data reading and writing operations available in pandas. This includes reading and writing text files, Parquet, HDF, JSON, and other formats from local, NFS, HDFS, or S3 storage. {numref}`dask-read-write-operations` illustrates some common reading and writing operations.\n",
    "\n",
    "```{table} some reading and writing operations in Dask DataFrame\n",
    ":name: dask-read-write-operations\n",
    "|   \t| CSV          \t| Parquet          \t| HDF          \t|\n",
    "|---\t|--------------\t|------------------\t|--------------\t|\n",
    "| Read  \t| [`read_csv()`](https://docs.dask.org/en/stable/generated/dask.dataframe.read_csv.html) \t| [`read_parquet()`](https://docs.dask.org/en/stable/generated/dask.dataframe.read_parquet.html) \t| [`read_hdf()`](https://docs.dask.org/en/stable/generated/dask.dataframe.read_hdf.html) \t|\n",
    "| Write  \t| [`to_csv()`](https://docs.dask.org/en/stable/generated/dask.dataframe.to_csv.html)   \t| [`to_parquet()`](https://docs.dask.org/en/stable/generated/dask.dataframe.to_parquet.html)   \t| [`to_hdf()`](https://docs.dask.org/en/stable/generated/dask.dataframe.to_hdf.html)   \t|\n",
    "```\n",
    "\n",
    "## File Systems\n",
    "\n",
    ":::{tip}\n",
    "When reading and writing data with Dask clusters, it is recommended to store the data in a shared file system such as NFS, HDFS, or S3, ensuring that all Dask workers can access the data.\n",
    ":::\n",
    "\n",
    "File system prefixes (i.e., Schemes) are commonly used in the industry to identify different file systems for reading and writing files. {numref}`uri-schemes` provides examples of several schemes. A dataset address should be a Uniform Resource Identifier (URI) consisting of a scheme and a specific address. The URI template is `scheme://path/to/data`. For example, `file:///tmp/tripdata.parquet` or `s3://tmp/tripdata.parquet`.\n",
    "\n",
    "```{table} URI Scheme\n",
    ":name: uri-schemes\n",
    "|        \t|   Local   \t|   S3  \t|  HDFS \t|\n",
    "|:------:\t|:--------:\t|:-----:\t|:--------:\t|\n",
    "| Scheme \t| file:// \t| s3:// \t| hdfs:// \t|\n",
    "```\n",
    "\n",
    "If no scheme is specified in the dataset address, it is assumed to be a locally accessible file system, i.e., a file system that the computing node can directly read, write, and access. For example, a Network File System (NFS) is a distributed file system mounted to the `/mnt/nfs` directory on multiple computing nodes. When using Dask to read and write to this directory, you can directly use `/mnt/nfs`.\n",
    "\n",
    "Later sections of this book, such as Ray Data, follow the same URI and scheme standards.\n",
    "\n",
    "Shared file systems like HDFS and S3 are often shared by multiple users in an enterprise or organization. Therefore, there is usually user authentication to ensure data isolation between users and prevent them from modifying or deleting each other's data. Different file systems have their own methods of user authentication. For instance, S3 users need to provide tokens, and these tokens can be passed into the `storage_options` parameter of methods like `read_*()` and `to_*()` (including `read_csv()`, `read_parquet()`, `to_parquet()`, etc.). If you are unfamiliar with user authentication, consult with colleagues responsible for operations and management in your organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Partitioning and Parallel Reading\n",
    "\n",
    "Let's use the example of reading Comma-Separated Values (CSV) files to illustrate the differences between Dask DataFrame and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/luweizheng/Projects/godaai/distributed-python-en/ch-dask-dataframe/../data/nycflights/*.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import urllib\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "folder_path = os.path.join(os.getcwd(), \"../data/\")\n",
    "download_url = \"https://storage.googleapis.com/dask-tutorial-data/nycflights.tar.gz\"\n",
    "tar_file_path = os.path.join(folder_path, \"nycflights.tar.gz\")\n",
    "if not os.path.exists(os.path.join(folder_path, \"nycflights\")):\n",
    "    urllib.request.urlretrieve(download_url, tar_file_path)\n",
    "    with tarfile.open(tar_file_path, mode=\"r:gz\") as flights:\n",
    "            flights.extractall(folder_path)\n",
    "        \n",
    "file_path = os.path.join(folder_path, \"nycflights\", \"*.csv\")\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask.distributed import LocalCluster, Client\n",
    "\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both pandas and Dask DataFrame provide the `read_csv()` method for reading CSV files. Dask's [`read_csv()`](https://docs.dask.org/en/stable/generated/dask.dataframe.read_csv.html) method has parameters almost identical to pandas, which you can refer to in the pandas' [`read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) documentation. In this example, the original data has many columns, and the first three columns are `Year`, `Month`, and `DayofMonth`. The `parse_dates` parameter of the `read_csv()` method is used to parse these three columns into the `datetime64` type and generate a new column `Date`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(file_path, parse_dates={'Date': [0, 1, 2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the `file_path` is in the form of `*.csv`, matching all files ending with `csv`. In contrast, pandas' `read_csv()` can only read a single file and does not support wildcards like `*.csv`. If you want to read all files ending with csv in a folder using pandas, you should:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(file_path)\n",
    "data = []\n",
    "\n",
    "for p in file_list:\n",
    "    df = pd.read_csv(p, parse_dates={'Date': [0, 1, 2]})\n",
    "    data.append(df)\n",
    "\n",
    "pdf = pd.concat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first three rows of this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>...</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  DayOfWeek  DepTime  CRSDepTime  ArrTime  CRSArrTime  \\\n",
       "0 1990-01-01          1   1621.0        1540   1747.0        1701   \n",
       "1 1990-01-02          2   1547.0        1540   1700.0        1701   \n",
       "2 1990-01-03          3   1546.0        1540   1710.0        1701   \n",
       "\n",
       "  UniqueCarrier  FlightNum  TailNum  ActualElapsedTime  ...  AirTime  \\\n",
       "0            US         33      NaN               86.0  ...      NaN   \n",
       "1            US         33      NaN               73.0  ...      NaN   \n",
       "2            US         33      NaN               84.0  ...      NaN   \n",
       "\n",
       "   ArrDelay  DepDelay  Origin Dest Distance  TaxiIn  TaxiOut  Cancelled  \\\n",
       "0      46.0      41.0     EWR  PIT    319.0     NaN      NaN          0   \n",
       "1      -1.0       7.0     EWR  PIT    319.0     NaN      NaN          0   \n",
       "2       9.0       6.0     EWR  PIT    319.0     NaN      NaN          0   \n",
       "\n",
       "   Diverted  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>...</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1990-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1990-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1990-01-03</td>\n",
       "      <td>3</td>\n",
       "      <td>1546.0</td>\n",
       "      <td>1540</td>\n",
       "      <td>1710.0</td>\n",
       "      <td>1701</td>\n",
       "      <td>US</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>EWR</td>\n",
       "      <td>PIT</td>\n",
       "      <td>319.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  DayOfWeek  DepTime  CRSDepTime  ArrTime  CRSArrTime  \\\n",
       "0 1990-01-01          1   1621.0        1540   1747.0        1701   \n",
       "1 1990-01-02          2   1547.0        1540   1700.0        1701   \n",
       "2 1990-01-03          3   1546.0        1540   1710.0        1701   \n",
       "\n",
       "  UniqueCarrier  FlightNum TailNum  ActualElapsedTime  ...  AirTime  ArrDelay  \\\n",
       "0            US         33     NaN               86.0  ...      NaN      46.0   \n",
       "1            US         33     NaN               73.0  ...      NaN      -1.0   \n",
       "2            US         33     NaN               84.0  ...      NaN       9.0   \n",
       "\n",
       "   DepDelay  Origin Dest Distance  TaxiIn  TaxiOut  Cancelled  Diverted  \n",
       "0      41.0     EWR  PIT    319.0     NaN      NaN          0         0  \n",
       "1       7.0     EWR  PIT    319.0     NaN      NaN          0         0  \n",
       "2       6.0     EWR  PIT    319.0     NaN      NaN          0         0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This highlights the difference between Dask DataFrame and pandas. Dask DataFrame accepts wildcards like `*.csv` and can read all files ending with csv in a folder in batches. Dask DataFrame first traverses the `*.csv` directory to understand how many CSV files are present. Then, when constructing the Task Graph, it parallelly initiates multiple pandas processes based on the number of files.\n",
    "\n",
    "`ddf.visualize()` visualizes the Task Graph, and you can see that for a directory with m CSV files, the Task Graph generates m `read_csv()` subgraphs. These subgraphs are executed by launching m pandas `read_csv()` processes in parallel. In other words, each CSV file corresponds to one Partition. Building the Task Graph based on the number of files is the most straightforward way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1770pt\" height=\"436pt\" viewBox=\"0.00 0.00 1770.21 436.28\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 432.28)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-432.28 1766.21,-432.28 1766.21,4 -4,4\"/>\n",
       "<!-- 5978823819242510818 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5978823819242510818</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"80.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- 5994421954963395744 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5994421954963395744</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"107.11,-160.07 53.11,-160.07 53.11,-124.07 107.11,-124.07 107.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- 5978823819242510818&#45;&gt;5994421954963395744 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5978823819242510818-&gt;5994421954963395744</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.11,-88.55C80.11,-96.66 80.11,-104.95 80.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"76.61,-112.36 80.11,-122.36 83.61,-112.36 76.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;4067968202281889255 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>-4067968202281889255</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"80.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- 5994421954963395744&#45;&gt;&#45;4067968202281889255 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5994421954963395744-&gt;-4067968202281889255</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.11,-160.34C80.11,-167.1 80.11,-175.4 80.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"76.61,-184.22 80.11,-194.22 83.61,-184.22 76.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;5383198043895348223 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>-5383198043895348223</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"258.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;5944681362644157447 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>-5944681362644157447</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"285.11,-160.07 231.11,-160.07 231.11,-124.07 285.11,-124.07 285.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- &#45;5383198043895348223&#45;&gt;&#45;5944681362644157447 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>-5383198043895348223-&gt;-5944681362644157447</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.11,-88.55C258.11,-96.66 258.11,-104.95 258.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.61,-112.36 258.11,-122.36 261.61,-112.36 254.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- 171350970157003353 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>171350970157003353</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"258.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;5944681362644157447&#45;&gt;171350970157003353 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>-5944681362644157447-&gt;171350970157003353</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.11,-160.34C258.11,-167.1 258.11,-175.4 258.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.61,-184.22 258.11,-194.22 261.61,-184.22 254.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;5542236254440823743 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>-5542236254440823743</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"436.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"436.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- 7608988682092697803 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7608988682092697803</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"463.11,-160.07 409.11,-160.07 409.11,-124.07 463.11,-124.07 463.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"436.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- &#45;5542236254440823743&#45;&gt;7608988682092697803 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>-5542236254440823743-&gt;7608988682092697803</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M436.11,-88.55C436.11,-96.66 436.11,-104.95 436.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.61,-112.36 436.11,-122.36 439.61,-112.36 432.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;632775934991569689 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>-632775934991569689</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"436.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"436.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- 7608988682092697803&#45;&gt;&#45;632775934991569689 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>7608988682092697803-&gt;-632775934991569689</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M436.11,-160.34C436.11,-167.1 436.11,-175.4 436.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.61,-184.22 436.11,-194.22 439.61,-184.22 432.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;7224164361316241908 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>-7224164361316241908</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"614.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;8728472018499223516 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>-8728472018499223516</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"641.11,-160.07 587.11,-160.07 587.11,-124.07 641.11,-124.07 641.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- &#45;7224164361316241908&#45;&gt;&#45;8728472018499223516 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>-7224164361316241908-&gt;-8728472018499223516</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.11,-88.55C614.11,-96.66 614.11,-104.95 614.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.61,-112.36 614.11,-122.36 617.61,-112.36 610.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;791814145537045209 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>-791814145537045209</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"614.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;8728472018499223516&#45;&gt;&#45;791814145537045209 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>-8728472018499223516-&gt;-791814145537045209</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.11,-160.34C614.11,-167.1 614.11,-175.4 614.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.61,-184.22 614.11,-194.22 617.61,-184.22 610.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;7383202571861717428 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>-7383202571861717428</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"792.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- 4825198026237631734 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>4825198026237631734</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"819.11,-160.07 765.11,-160.07 765.11,-124.07 819.11,-124.07 819.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<!-- &#45;7383202571861717428&#45;&gt;4825198026237631734 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>-7383202571861717428-&gt;4825198026237631734</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M792.11,-88.55C792.11,-96.66 792.11,-104.95 792.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.61,-112.36 792.11,-122.36 795.61,-112.36 788.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- 5415106863307802243 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>5415106863307802243</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"792.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- 4825198026237631734&#45;&gt;5415106863307802243 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>4825198026237631734-&gt;5415106863307802243</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M792.11,-160.34C792.11,-167.1 792.11,-175.4 792.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.61,-184.22 792.11,-194.22 795.61,-184.22 788.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- 5432094836517797849 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5432094836517797849</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"970.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"970.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;7113905291369921457 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>-7113905291369921457</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"997.11,-160.07 943.11,-160.07 943.11,-124.07 997.11,-124.07 997.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"970.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<!-- 5432094836517797849&#45;&gt;&#45;7113905291369921457 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5432094836517797849-&gt;-7113905291369921457</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M970.11,-88.55C970.11,-96.66 970.11,-104.95 970.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"966.61,-112.36 970.11,-122.36 973.61,-112.36 966.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;8792318037962856765 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>-8792318037962856765</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"970.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"970.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;7113905291369921457&#45;&gt;&#45;8792318037962856765 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>-7113905291369921457-&gt;-8792318037962856765</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M970.11,-160.34C970.11,-167.1 970.11,-175.4 970.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"966.61,-184.22 970.11,-194.22 973.61,-184.22 966.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;2418061357265632018 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>-2418061357265632018</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1148.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1148.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;606264535267923032 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>-606264535267923032</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1175.11,-160.07 1121.11,-160.07 1121.11,-124.07 1175.11,-124.07 1175.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"1148.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">6</text>\n",
       "</g>\n",
       "<!-- &#45;2418061357265632018&#45;&gt;&#45;606264535267923032 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>-2418061357265632018-&gt;-606264535267923032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1148.11,-88.55C1148.11,-96.66 1148.11,-104.95 1148.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1144.61,-112.36 1148.11,-122.36 1151.61,-112.36 1144.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;8264227128287975233 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>-8264227128287975233</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1148.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"1148.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;606264535267923032&#45;&gt;&#45;8264227128287975233 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>-606264535267923032-&gt;-8264227128287975233</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1148.11,-160.34C1148.11,-167.1 1148.11,-175.4 1148.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1144.61,-184.22 1148.11,-194.22 1151.61,-184.22 1144.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;3454900769537952661 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>-3454900769537952661</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1326.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1326.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- 8549048126484564090 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>8549048126484564090</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1353.11,-160.07 1299.11,-160.07 1299.11,-124.07 1353.11,-124.07 1353.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"1326.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">7</text>\n",
       "</g>\n",
       "<!-- &#45;3454900769537952661&#45;&gt;8549048126484564090 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>-3454900769537952661-&gt;8549048126484564090</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1326.11,-88.55C1326.11,-96.66 1326.11,-104.95 1326.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1322.61,-112.36 1326.11,-122.36 1329.61,-112.36 1322.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;8225534206351139483 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>-8225534206351139483</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1326.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"1326.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- 8549048126484564090&#45;&gt;&#45;8225534206351139483 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>8549048126484564090-&gt;-8225534206351139483</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1326.11,-160.34C1326.11,-167.1 1326.11,-175.4 1326.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1322.61,-184.22 1326.11,-194.22 1329.61,-184.22 1322.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- 3629821441033739914 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>3629821441033739914</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1504.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1504.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;3390055191122989101 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>-3390055191122989101</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1531.11,-160.07 1477.11,-160.07 1477.11,-124.07 1531.11,-124.07 1531.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"1504.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">8</text>\n",
       "</g>\n",
       "<!-- 3629821441033739914&#45;&gt;&#45;3390055191122989101 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>3629821441033739914-&gt;-3390055191122989101</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1504.11,-88.55C1504.11,-96.66 1504.11,-104.95 1504.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1500.61,-112.36 1504.11,-122.36 1507.61,-112.36 1500.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- &#45;4864016235639091998 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>-4864016235639091998</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1504.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"1504.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;3390055191122989101&#45;&gt;&#45;4864016235639091998 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>-3390055191122989101-&gt;-4864016235639091998</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1504.11,-160.34C1504.11,-167.1 1504.11,-175.4 1504.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1500.61,-184.22 1504.11,-194.22 1507.61,-184.22 1500.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- 7869140613472632522 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>7869140613472632522</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1682.11\" cy=\"-44.03\" rx=\"44.03\" ry=\"44.03\"/>\n",
       "<text text-anchor=\"middle\" x=\"1682.11\" y=\"-38.23\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">read-csv</text>\n",
       "</g>\n",
       "<!-- &#45;8283129220095685467 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>-8283129220095685467</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1709.11,-160.07 1655.11,-160.07 1655.11,-124.07 1709.11,-124.07 1709.11,-160.07\"/>\n",
       "<text text-anchor=\"middle\" x=\"1682.11\" y=\"-136.27\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">9</text>\n",
       "</g>\n",
       "<!-- 7869140613472632522&#45;&gt;&#45;8283129220095685467 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7869140613472632522-&gt;-8283129220095685467</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1682.11,-88.55C1682.11,-96.66 1682.11,-104.95 1682.11,-112.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1678.61,-112.36 1682.11,-122.36 1685.61,-112.36 1678.61,-112.36\"/>\n",
       "</g>\n",
       "<!-- 8380243549937518448 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>8380243549937518448</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1682.11\" cy=\"-276.17\" rx=\"80.11\" ry=\"80.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"1682.11\" y=\"-270.37\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">to_pyarrow_string</text>\n",
       "</g>\n",
       "<!-- &#45;8283129220095685467&#45;&gt;8380243549937518448 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>-8283129220095685467-&gt;8380243549937518448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1682.11,-160.34C1682.11,-167.1 1682.11,-175.4 1682.11,-184.42\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1678.61,-184.22 1682.11,-194.22 1685.61,-184.22 1678.61,-184.22\"/>\n",
       "</g>\n",
       "<!-- &#45;3954132327406732060 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>-3954132327406732060</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"107.11,-428.28 53.11,-428.28 53.11,-392.28 107.11,-392.28 107.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"80.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">0</text>\n",
       "</g>\n",
       "<!-- &#45;4067968202281889255&#45;&gt;&#45;3954132327406732060 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>-4067968202281889255-&gt;-3954132327406732060</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M80.11,-356.69C80.11,-365.23 80.11,-373.46 80.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"76.61,-380.58 80.11,-390.58 83.61,-380.58 76.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;8847206356379428426 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>-8847206356379428426</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"285.11,-428.28 231.11,-428.28 231.11,-392.28 285.11,-392.28 285.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"258.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<!-- 171350970157003353&#45;&gt;&#45;8847206356379428426 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>171350970157003353-&gt;-8847206356379428426</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M258.11,-356.69C258.11,-365.23 258.11,-373.46 258.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.61,-380.58 258.11,-390.58 261.61,-380.58 254.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;2339565600277430001 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>-2339565600277430001</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"463.11,-428.28 409.11,-428.28 409.11,-392.28 463.11,-392.28 463.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"436.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">2</text>\n",
       "</g>\n",
       "<!-- &#45;632775934991569689&#45;&gt;&#45;2339565600277430001 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>-632775934991569689-&gt;-2339565600277430001</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M436.11,-356.69C436.11,-365.23 436.11,-373.46 436.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.61,-380.58 436.11,-390.58 439.61,-380.58 432.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;7232639629250126367 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>-7232639629250126367</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"641.11,-428.28 587.11,-428.28 587.11,-392.28 641.11,-392.28 641.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"614.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">3</text>\n",
       "</g>\n",
       "<!-- &#45;791814145537045209&#45;&gt;&#45;7232639629250126367 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>-791814145537045209-&gt;-7232639629250126367</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.11,-356.69C614.11,-365.23 614.11,-373.46 614.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"610.61,-380.58 614.11,-390.58 617.61,-380.58 610.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;5123356256132496070 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>-5123356256132496070</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"819.11,-428.28 765.11,-428.28 765.11,-392.28 819.11,-392.28 819.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"792.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<!-- 5415106863307802243&#45;&gt;&#45;5123356256132496070 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>5415106863307802243-&gt;-5123356256132496070</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M792.11,-356.69C792.11,-365.23 792.11,-373.46 792.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"788.61,-380.58 792.11,-390.58 795.61,-380.58 788.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- 8430313788604359180 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>8430313788604359180</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"997.11,-428.28 943.11,-428.28 943.11,-392.28 997.11,-392.28 997.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"970.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<!-- &#45;8792318037962856765&#45;&gt;8430313788604359180 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>-8792318037962856765-&gt;8430313788604359180</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M970.11,-356.69C970.11,-365.23 970.11,-373.46 970.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"966.61,-380.58 970.11,-390.58 973.61,-380.58 966.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;3508789529003194011 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>-3508789529003194011</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1175.11,-428.28 1121.11,-428.28 1121.11,-392.28 1175.11,-392.28 1175.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"1148.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">6</text>\n",
       "</g>\n",
       "<!-- &#45;8264227128287975233&#45;&gt;&#45;3508789529003194011 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>-8264227128287975233-&gt;-3508789529003194011</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1148.11,-356.69C1148.11,-365.23 1148.11,-373.46 1148.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1144.61,-380.58 1148.11,-390.58 1151.61,-380.58 1144.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- 2998851227098804414 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>2998851227098804414</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1353.11,-428.28 1299.11,-428.28 1299.11,-392.28 1353.11,-392.28 1353.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"1326.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">7</text>\n",
       "</g>\n",
       "<!-- &#45;8225534206351139483&#45;&gt;2998851227098804414 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>-8225534206351139483-&gt;2998851227098804414</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1326.11,-356.69C1326.11,-365.23 1326.11,-373.46 1326.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1322.61,-380.58 1326.11,-390.58 1329.61,-380.58 1322.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- &#45;6292580184858260080 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>-6292580184858260080</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1531.11,-428.28 1477.11,-428.28 1477.11,-392.28 1531.11,-392.28 1531.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"1504.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">8</text>\n",
       "</g>\n",
       "<!-- &#45;4864016235639091998&#45;&gt;&#45;6292580184858260080 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>-4864016235639091998-&gt;-6292580184858260080</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1504.11,-356.69C1504.11,-365.23 1504.11,-373.46 1504.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1500.61,-380.58 1504.11,-390.58 1507.61,-380.58 1500.61,-380.58\"/>\n",
       "</g>\n",
       "<!-- 215060571243738345 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>215060571243738345</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"1709.11,-428.28 1655.11,-428.28 1655.11,-392.28 1709.11,-392.28 1709.11,-428.28\"/>\n",
       "<text text-anchor=\"middle\" x=\"1682.11\" y=\"-404.48\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">9</text>\n",
       "</g>\n",
       "<!-- 8380243549937518448&#45;&gt;215060571243738345 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>8380243549937518448-&gt;215060571243738345</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1682.11,-356.69C1682.11,-365.23 1682.11,-373.46 1682.11,-380.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1678.61,-380.58 1682.11,-390.58 1685.61,-380.58 1678.61,-380.58\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.visualize(filename=\"../img/ch-dask-dataframe/nyc-flights-graph\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, Dask determines the number of partitions based on the number of files. As mentioned in {numref}`dask-task-graph`, splitting data too finely or too coarsely is not ideal for all scenarios. Getting the number of partitions based on the number of files may not be optimal for every situation. If there are many small files, the granularity may be too fine. On the other hand, if it's a single large file, the granularity may be too coarse, potentially leading to out-of-memory (OOM) issues. In these extreme cases, the generated Task Graph may not be optimal.\n",
    "Dask DataFrame's `read_csv()` provides a parameter, `blocksize`, allowing users to customize the size of each partition. The size of an individual partition will not exceed the specified `blocksize`. If users do not explicitly set `blocksize`, Dask DataFrame will determine the `blocksize` based on the detected computational resources, with a maximum of 64MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferring Data Types\n",
    "\n",
    "Dask DataFrame infers datatypes and records details such as field names and their corresponding data types as schema. The `read_csv()` function in Dask DataFrame introduces a `sample` parameter, indicating the system to read only the initial `sample` bytes of data. The data types are inferred based on this limited dataset. However, this approach poses certain challenges:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the last 3 rows of the `ddf`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 17:57:34,915 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('to_pyarrow_string-740f4fb47361d8d6d73742e5f29cf9c8', 9)\n",
      "Function:  execute_task\n",
      "args:      ((subgraph_callable-d2801090-22cc-4476-8ac9-fa6fe94fa7a9, [(<function read_block_from_file at 0x10e301260>, <OpenFile '/Users/luweizheng/Projects/godaai/distributed-python-en/ch-dask-dataframe/../data/nycflights/1999.csv'>, 0, 25952466, b'\\n'), None, True, True]))\n",
      "kwargs:    {}\n",
      "Exception: 'ValueError(\\'Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\\\\n\\\\n+----------------+---------+----------+\\\\n| Column         | Found   | Expected |\\\\n+----------------+---------+----------+\\\\n| CRSElapsedTime | float64 | int64    |\\\\n| TailNum        | object  | float64  |\\\\n+----------------+---------+----------+\\\\n\\\\nThe following columns also raised exceptions on conversion:\\\\n\\\\n- TailNum\\\\n  ValueError(\"could not convert string to float: \\\\\\'N54711\\\\\\'\")\\\\n\\\\nUsually this is due to dask\\\\\\'s dtype inference failing, and\\\\n*may* be fixed by specifying dtypes manually by adding:\\\\n\\\\ndtype={\\\\\\'CRSElapsedTime\\\\\\': \\\\\\'float64\\\\\\',\\\\n       \\\\\\'TailNum\\\\\\': \\\\\\'object\\\\\\'}\\\\n\\\\nto the call to `read_csv`/`read_table`.\\')'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/4n/v40br47s46ggrjm9bdm64lwh0000gn/T/ipykernel_61452/3690877535.py\", line 3, in <module>\n",
      "    ddf.tail(3)\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/dataframe/core.py\", line 1591, in tail\n",
      "    result = result.compute()\n",
      "             ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/base.py\", line 342, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/base.py\", line 628, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/dataframe/io/csv.py\", line 142, in __call__\n",
      "    df = pandas_read_text(\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/dataframe/io/csv.py\", line 197, in pandas_read_text\n",
      "    coerce_dtypes(df, dtypes)\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/dask/dataframe/io/csv.py\", line 298, in coerce_dtypes\n",
      "    raise ValueError(msg)\n",
      "    ^^^^^^^^^^^^^^^^^\n",
      "ValueError: Mismatched dtypes found in `pd.read_csv`/`pd.read_table`.\n",
      "\n",
      "+----------------+---------+----------+\n",
      "| Column         | Found   | Expected |\n",
      "+----------------+---------+----------+\n",
      "| CRSElapsedTime | float64 | int64    |\n",
      "| TailNum        | object  | float64  |\n",
      "+----------------+---------+----------+\n",
      "\n",
      "The following columns also raised exceptions on conversion:\n",
      "\n",
      "- TailNum\n",
      "  ValueError(\"could not convert string to float: 'N54711'\")\n",
      "\n",
      "Usually this is due to dask's dtype inference failing, and\n",
      "*may* be fixed by specifying dtypes manually by adding:\n",
      "\n",
      "dtype={'CRSElapsedTime': 'float64',\n",
      "       'TailNum': 'object'}\n",
      "\n",
      "to the call to `read_csv`/`read_table`.\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "try:\n",
    "    ddf.tail(3)\n",
    "except Exception:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ddf.tail(3)` throws an exception. Why did it raise an exception? Because Dask DataFrame did not read all the data but only the first `sample`-sized portion. In this `sample`-size data, the `CRSElapsedTime` column is empty. Dask DataFrame guessed this field to be of type `float64`, but in later rows, `CRSElapsedTime` is `int64`. In other words, the inferred data type by Dask DataFrame does not match the actual data type encountered.\n",
    "\n",
    "To address this issue, it's recommended to explicitly specify the data types at the beginning when reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>TailNum</th>\n",
       "      <th>ActualElapsedTime</th>\n",
       "      <th>...</th>\n",
       "      <th>AirTime</th>\n",
       "      <th>ArrDelay</th>\n",
       "      <th>DepDelay</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>Distance</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>Diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269178</th>\n",
       "      <td>1999-12-29</td>\n",
       "      <td>3</td>\n",
       "      <td>1646.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>1846.0</td>\n",
       "      <td>1901</td>\n",
       "      <td>UA</td>\n",
       "      <td>1753</td>\n",
       "      <td>N592UA</td>\n",
       "      <td>240.0</td>\n",
       "      <td>...</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269179</th>\n",
       "      <td>1999-12-30</td>\n",
       "      <td>4</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>1908.0</td>\n",
       "      <td>1901</td>\n",
       "      <td>UA</td>\n",
       "      <td>1753</td>\n",
       "      <td>N575UA</td>\n",
       "      <td>257.0</td>\n",
       "      <td>...</td>\n",
       "      <td>233.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269180</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>5</td>\n",
       "      <td>1642.0</td>\n",
       "      <td>1645</td>\n",
       "      <td>1851.0</td>\n",
       "      <td>1901</td>\n",
       "      <td>UA</td>\n",
       "      <td>1753</td>\n",
       "      <td>N539UA</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>LGA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1619.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date  DayOfWeek  DepTime  CRSDepTime  ArrTime  CRSArrTime  \\\n",
       "269178 1999-12-29          3   1646.0        1645   1846.0        1901   \n",
       "269179 1999-12-30          4   1651.0        1645   1908.0        1901   \n",
       "269180 1999-12-31          5   1642.0        1645   1851.0        1901   \n",
       "\n",
       "       UniqueCarrier  FlightNum TailNum  ActualElapsedTime  ...  AirTime  \\\n",
       "269178            UA       1753  N592UA              240.0  ...    220.0   \n",
       "269179            UA       1753  N575UA              257.0  ...    233.0   \n",
       "269180            UA       1753  N539UA              249.0  ...    232.0   \n",
       "\n",
       "        ArrDelay  DepDelay  Origin Dest Distance  TaxiIn  TaxiOut  Cancelled  \\\n",
       "269178     -15.0       1.0     LGA  DEN   1619.0     5.0     15.0      False   \n",
       "269179       7.0       6.0     LGA  DEN   1619.0     5.0     19.0      False   \n",
       "269180     -10.0      -3.0     LGA  DEN   1619.0     6.0     11.0      False   \n",
       "\n",
       "        Diverted  \n",
       "269178         0  \n",
       "269179         0  \n",
       "269180         0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dd.read_csv(file_path,\n",
    "                 parse_dates={'Date': [0, 1, 2]},\n",
    "                 dtype={'TailNum': object,\n",
    "                        'CRSElapsedTime': float,\n",
    "                        'Cancelled': bool})\n",
    "ddf.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the `blocksize` parameter with values of `50,000` and `5,000,000`. We can compare the speed under different partitions and observe various information provided on the Dask Dashboard. When `blocksize` is set to `50,000`, the Task Graph has a finer granularity, resulting in a larger and more complex Task Graph, making the overall processing time longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "EWR    1139451\n",
      "JFK     427243\n",
      "LGA     974267\n",
      "Name: Origin, dtype: int64\n",
      "CPU times: user 3.04 s, sys: 1.04 s, total: 4.08 s\n",
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ddf = dd.read_csv(file_path, \n",
    "                parse_dates={\"Date\": [0, 1, 2]},\n",
    "                dtype={\"TailNum\": str, \"CRSElapsedTime\": float, \"Cancelled\": bool},\n",
    "                blocksize=50_000)\n",
    "\n",
    "origin_cnt = ddf[~ddf.Cancelled].groupby(\"Origin\").Origin.count().compute()\n",
    "print(origin_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin\n",
      "EWR    1139451\n",
      "JFK     427243\n",
      "LGA     974267\n",
      "Name: Origin, dtype: int64\n",
      "CPU times: user 82.6 ms, sys: 21.8 ms, total: 104 ms\n",
      "Wall time: 833 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ddf = dd.read_csv(file_path, \n",
    "                parse_dates={\"Date\": [0, 1, 2]},\n",
    "                dtype={\"TailNum\": str, \"CRSElapsedTime\": float, \"Cancelled\": bool},\n",
    "                blocksize=5_000_000)\n",
    "\n",
    "origin_cnt = ddf[~ddf.Cancelled].groupby(\"Origin\").Origin.count().compute()\n",
    "print(origin_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet\n",
    "\n",
    "In the realm of big data engineering, [Apache Parquet](https://parquet.apache.org/) is a widely adopted file format. Compared to pure text file types like CSV, Parquet offers the following advantages:\n",
    "\n",
    "* Columnar storage\n",
    "* Embedded schema\n",
    "* Data compression\n",
    "\n",
    "Columnar storage organizes data by columns instead of rows. Specifically, unlike CSV, which stores data by rows, Parquet stores data via columns. Data analysts are usually interested in specific columns rather than all of them. Parquet allows convenient filtering of unnecessary columns during data reading, resulting in improved performance by reducing the amount of data to be read. Parquet is extensively used in the Apache Spark, Apache Hive, and Apache Flink ecosystems. Parquet inherently includes schema information, embedding metadata such as column names and data types for each column within each Parquet file. This feature eliminates inaccuracies in data types inferring of Dask DataFrame. Data in Parquet is compressed, making it more space-efficient compared to CSV.\n",
    "\n",
    "For instance, it is advisable to read only the necessary columns rather than all of them:\n",
    "\n",
    "```python\n",
    "dd.read_parquet(\n",
    "    \"s3://path/to/parquet/\",\n",
    "    columns=[\"a\", \"b\", \"c\"]\n",
    ")\n",
    "```\n",
    "\n",
    "Additionally, Parquet introduces the concept of Row Groups, as illustrated in {numref}`parquet-row-group`. Data in a Parquet file is grouped into Row Groups, defining the number of rows within each group. In the example, there are three Row Groups, each containing two rows of data. Each Row Group stores metadata such as maximum and minimum values of their columns. When querying certain columns, metadata helps determine whether to read a specific Row Group, minimizing unnecessary data retrieval.\n",
    "For example, if a column represents a time series, and a query involves \"sales from 9:00 to 12:00 every day,\" the metadata within the Row Group records the maximum and minimum values of the time column. By utilizing this metadata, it becomes possible to determine whether it is necessary to read the specific Row Group.\n",
    "\n",
    "```{figure} ../img/ch-dask-dataframe/parquet-row-group.svg\n",
    "---\n",
    "width: 600px\n",
    "name: parquet-row-group\n",
    "---\n",
    "Parquet Columnar Storage with Row Groups\n",
    "```\n",
    "\n",
    "With Row Groups, a Parquet file may contain multiple groups. However, many Parquet files have only one Row Group.\n",
    "\n",
    "Typically, enterprise data files are split into multiple Parquet files and organized in a specific manner, such as by time:\n",
    "\n",
    "```\n",
    "/path/folder/\n",
    ".../year/month/day.parquet\n",
    "```\n",
    "\n",
    "When Dask DataFrame reads a Parquet dataset, it considers both file numbers and Row Groups for partitioning. If there are m files, the potential partitioning options are:\n",
    "\n",
    "* Each Parquet file corresponds to one Dask partition, resulting in m partitions.\n",
    "* Each Row Group corresponds to one Dask partition. If a Parquet file has n Row Groups, there are m * n partitions.\n",
    "\n",
    "It is crucial to ensure that the partition's memory usage does not exceed the Worker's physical memory. Dask DataFrame's `read_parquet()` provides users with more options through the `split_row_groups` parameter. Setting it to `split_row_groups=True` enforces one partition per Row Group, while setting it to `False` results in one partition per complete file. The default is `split_row_groups=\"infer\"`, where Dask DataFrame infers whether each complete file or each Row Group corresponds to a partition, by leveraging the file size of the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

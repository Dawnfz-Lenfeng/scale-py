{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ray-data-preprocessor)=\n",
    "# Preprocessor\n",
    "\n",
    "{numref}`ray-data-transform` introduces the general interfaces `map()` and `map_batches()`. For structured tabular data, Ray Data introduces a high-level API called the Preprocessor, building upon `map()` and `map_batches`. [Preprocessor](https://docs.ray.io/en/latest/data/api/preprocessor.html) consists of a series of feature processing operations, providing better integration with machine learning model training and inference. It is similar to scikit-learn's [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing), making it easy for scikit-learn users transfering quickly. For unstructured data such as images or videos, it is still recommended to use `map()` or `map_batches()`.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Preprocessor primarily consists of four types of operations:\n",
    "\n",
    "1. [`fit()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessor.Preprocessor.fit.html): Computes the state information for the Ray Data `Dataset`, such as calculating the variance or mean of a column.\n",
    "2. [`transform()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessor.Preprocessor.transform.html): Executes the transformation operation. If the transformation operation involves state, `fit()` must be performed first.\n",
    "3. [`transform_batch()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessor.Preprocessor.transform_batch.html): Performs the transformation operation on a batch of data.\n",
    "4. [`fit_transform()`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessor.Preprocessor.fit_transform.html): An operation combining `fit()` and `transform()`. It first performs `fit()` on the `Dataset` and then applies `transform()`.\n",
    "\n",
    "Below, we will demonstrate how to use the Preprocessor based on the taxi dataset. The taxi dataset is a typical structured dataset with many columns, such as the distance of the journey. These columns can be used as features for machine learning algorithms. However, before feeding them into a machine learning model, feature processing is required. For instance, using [`MinMaxScaler`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.MinMaxScaler.html) to normalize features:\n",
    "\n",
    "$$\n",
    "x' = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:45:46,678\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "from typing import Any, Dict\n",
    "\n",
    "import ray\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "\n",
    "ray.init()\n",
    "\n",
    "folder_path = os.path.join(os.getcwd(), \"../data/nyc-taxi\")\n",
    "download_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-06.parquet\"\n",
    "file_name = download_url.split(\"/\")[-1]\n",
    "parquet_file_path = os.path.join(folder_path, file_name)\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "    with urllib.request.urlopen(download_url) as response, open(parquet_file_path, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3df4a7d82b4578a91298a55a5d8cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parquet Files Sample 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:45:48,122\tINFO dataset.py:2488 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-02-15 09:45:48,125\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=173 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-15 09:45:48,125\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 173, each read task output is split into 173 smaller blocks.\n",
      "2024-02-15 09:45:48,126\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> LimitOperator[limit=1]\n",
      "2024-02-15 09:45:48,126\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-15 09:45:48,126\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c826785493b240cb8490bad74ea75b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=938)\u001b[0m /Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by mode='default'.\n",
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=938)\u001b[0m   return transform_pyarrow.concat(tables)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'trip_distance': 3.4}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.data.preprocessors import MinMaxScaler\n",
    "\n",
    "ds = ray.data.read_parquet(parquet_file_path,\n",
    "    columns=[\"trip_distance\"])\n",
    "ds.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization with `MinMaxScaler`, the original values are transformed into normalized values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:45:48,278\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=173 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-15 09:45:48,279\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 173, each read task output is split into 173 smaller blocks.\n",
      "2024-02-15 09:45:48,279\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-02-15 09:45:48,279\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-15 09:45:48,280\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278bb014b5ed4b6cb1f2556a23d37116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07c42968024818b5a8548a6fea7dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357cdd17e5e24d379d21778d40c901ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8554bc09e94a4a78b45b7938c4b6d06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:45:49,101\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=173 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-15 09:45:49,101\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 173, each read task output is split into 173 smaller blocks.\n",
      "2024-02-15 09:45:49,102\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(MinMaxScaler._transform_pandas)] -> LimitOperator[limit=1]\n",
      "2024-02-15 09:45:49,102\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-15 09:45:49,102\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4574275eb4cd49afa5519987841a2832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=964)\u001b[0m /Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by mode='default'.\n",
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=964)\u001b[0m   return transform_pyarrow.concat(tables)\n",
      "/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'trip_distance': 1.8353531664835362e-05}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = MinMaxScaler(columns=[\"trip_distance\"])\n",
    "preprocessor.fit(ds)\n",
    "minmax_ds = preprocessor.transform(ds)\n",
    "minmax_ds.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/preprocessor.py:125: UserWarning: `fit` has already been called on the preprocessor (or at least one contained preprocessors if this is a chain). All previously fitted state will be overwritten!\n",
      "  warnings.warn(\n",
      "2024-02-15 09:45:49,257\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=173 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-15 09:45:49,257\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 173, each read task output is split into 173 smaller blocks.\n",
      "2024-02-15 09:45:49,258\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-02-15 09:45:49,258\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-15 09:45:49,258\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f322c2220bcc4dcf976d40a29647a244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5808b43752b14009a920485528043a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e20ef3b29df46558935985997e90d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dabe40cf75d411d9daa281331d08d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 09:45:49,490\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=173 for stage ReadParquet to satisfy output blocks of size at least DataContext.get_current().target_min_block_size=1.0MiB.\n",
      "2024-02-15 09:45:49,490\tINFO set_read_parallelism.py:122 -- To satisfy the requested parallelism of 173, each read task output is split into 173 smaller blocks.\n",
      "2024-02-15 09:45:49,490\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadParquet] -> TaskPoolMapOperator[MapBatches(MinMaxScaler._transform_pandas)] -> LimitOperator[limit=1]\n",
      "2024-02-15 09:45:49,491\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-02-15 09:45:49,491\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375effde3cbb4d3fb3c983e99aa8c64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=968)\u001b[0m /Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/arrow_block.py:148: FutureWarning: promote has been superseded by mode='default'.\n",
      "\u001b[36m(ReadParquet->SplitBlocks(173) pid=968)\u001b[0m   return transform_pyarrow.concat(tables)\n",
      "/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if isinstance(items[0], TensorArrayElement):\n",
      "/Users/luweizheng/miniconda3/envs/dispy/lib/python3.11/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return items[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'trip_distance': 1.8353531664835362e-05}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmax_ds_ft = preprocessor.fit_transform(ds)\n",
    "minmax_ds_ft.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical and Numerical Variables\n",
    "\n",
    "### Categorical Variables\n",
    "\n",
    "Machine learning models cannot directly handle categorical variables. Therefore, some transformations are required. The table below lists several Preprocessors for handling categorical variables.\n",
    "\n",
    "```{table} Preprocessors for handling categorical variables\n",
    ":name: categorical-data-preprocessor\n",
    "\n",
    "| Preprocessor       \t| Variable Type \t| Example                         \t|\n",
    "|--------------------\t|---------------\t|---------------------------------\t|\n",
    "| [`LabelEncoder`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.LabelEncoder.html)     \t| Unordered      \t| Cat, Dog, Cow, Sheep            \t|\n",
    "| [`OrdinalEncoder`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.OrdinalEncoder.html)     \t| Ordered        \t| High School, Bachelor's, Master's, Ph.D.    \t|\n",
    "| [`MultiHotEncoder`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.MultiHotEncoder.html) \t| Multi-class    \t| [\"Comedy\", \"Animation\"], [\"Suspense\", \"Action\"]   \t|\n",
    "```\n",
    "\n",
    "### Numerical Variables\n",
    "\n",
    "Various transformations can be applied to adapt the data for specific machine learning models. The table below lists several preprocessors for handling numerical variables.\n",
    "\n",
    "```{table} Preprocessors for handling numerical variables\n",
    ":name: numerical-data-preprocessor\n",
    "\n",
    "| Preprocessor       \t| Variable Type        \t| Computation                                \t| Remarks                                              \t|\n",
    "|--------------------\t|----------------------\t|--------------------------------------------\t|------------------------------------------------------\t|\n",
    "| [`RobustScaler`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.RobustScaler.html)     \t| With Outliers        \t| $x' = \\frac{x - \\mu_{1/2}}{\\mu_h - \\mu_l}$ \t| $\\mu_{1/2}$ is the median, $\\mu_h$ is the max, $\\mu_l$ is the min \t|\n",
    "| [`MaxAbsScaler`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.MaxAbsScaler.html)     \t| Sparse Data          \t| $x' = \\frac{x}{\\max{\\vert x \\vert}}$       \t|                                                      \t|\n",
    "| [`PowerTransformer`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.PowerTransformer.html) \t| Gaussian Transformation | Yeo-Johnson or Box-Cox                    \t|                                                      \t|\n",
    "| [`Normalizer`](https://docs.ray.io/en/latest/data/api/doc/ray.data.preprocessors.Normalizer.html)       \t| Requires Normalization \t| $x' = \\frac{x}{\\lVert x \\rVert_p}$         \t| $p$ is the norm, e.g., `l1` norm is the sum of absolute values         \t|\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
